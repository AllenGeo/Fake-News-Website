{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-cors\n",
      "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: Flask>=0.9 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from flask-cors) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from Flask>=0.9->flask-cors) (1.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\allen\\anaconda3\\lib\\site-packages (from click>=8.1.3->Flask>=0.9->flask-cors) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\allen\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=0.9->flask-cors) (2.1.3)\n",
      "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Installing collected packages: flask-cors\n",
      "Successfully installed flask-cors-5.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tfidf_vectorizer.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_bidirectional_lstm_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Load TF-IDF vectorizer and LabelEncoder (Make sure these were saved after training)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_vectorizer.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Load your trained TF-IDF vectorizer\u001b[39;00m\n\u001b[0;32m     19\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_encoder.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Load the LabelEncoder for 'subject'\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Function to process the title and content using TF-IDF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\allen\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tfidf_vectorizer.pkl'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the BiLSTM model\n",
    "model = load_model('trained_bidirectional_lstm_model.h5')\n",
    "\n",
    "# Load TF-IDF vectorizer and LabelEncoder (Make sure these were saved after training)\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')  # Load your trained TF-IDF vectorizer\n",
    "label_encoder = joblib.load('label_encoder.pkl')  # Load the LabelEncoder for 'subject'\n",
    "\n",
    "# Function to process the title and content using TF-IDF\n",
    "def get_tfidf_embeddings(text, tfidf_vectorizer):\n",
    "    return tfidf_vectorizer.transform([text]).toarray().squeeze()\n",
    "\n",
    "# Function to process the subject with LabelEncoder\n",
    "def encode_subject(subject, label_encoder):\n",
    "    return label_encoder.transform([subject])[0]  # Return the encoded value for subject\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    title = data.get('title', '')\n",
    "    content = data.get('content', '')\n",
    "    subject = data.get('subject', '')\n",
    "    date = data.get('date', '')\n",
    "\n",
    "    # Process the text using TF-IDF\n",
    "    title_tfidf = get_tfidf_embeddings(title, tfidf_vectorizer)\n",
    "    content_tfidf = get_tfidf_embeddings(content, tfidf_vectorizer)\n",
    "\n",
    "    # Combine the title and content TF-IDF embeddings\n",
    "    combined_text_features = np.concatenate([title_tfidf, content_tfidf])\n",
    "\n",
    "    # Encode the subject using LabelEncoder\n",
    "    encoded_subject = encode_subject(subject, label_encoder)\n",
    "\n",
    "    # Process the date (You can split date into various components: year, month, day)\n",
    "    date_obj = datetime.strptime(date, '%Y-%m-%d')  # Assuming date is in 'YYYY-MM-DD' format\n",
    "    date_features = np.array([date_obj.year, date_obj.month, date_obj.day, date_obj.weekday()])\n",
    "\n",
    "    # Combine all features into a single input array for the model\n",
    "    input_features = np.concatenate([combined_text_features, [encoded_subject], date_features])\n",
    "\n",
    "    # Reshape input_features if needed, based on your model's input format\n",
    "    input_features = input_features.reshape(1, -1)  # Adjust shape to fit your model's expected input\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(input_features)\n",
    "    predicted_label = np.argmax(prediction, axis=1)[0]  # Get the class with the highest probability\n",
    "\n",
    "    return jsonify({'target': int(predicted_label)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
